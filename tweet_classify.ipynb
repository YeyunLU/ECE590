{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "xQzcchnLt_xm",
    "outputId": "bbe5f98b-e378-4d52-e670-223f692b7a62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 80175\n",
      "valid: 11759\n",
      "test: 14960\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def loaddata(dataFile): #load data line by line\n",
    "    data = pd.read_csv(dataFile, sep='\\n', header=None)\n",
    "    data.columns = ['data']\n",
    "    data[['lan', 'tweet']] = data['data'].str.split('\\t', expand=True)\n",
    "    data['tweet'] = data['tweet'].str.lower().map(\n",
    "        lambda x: re.sub(r'\\W+', '', x))  # remove regular char\n",
    "    data['tweet'] = data['tweet'].map(\n",
    "        lambda x: re.sub(r'\\d+', '', x))  # remove digits\n",
    "    return data['tweet'],data['lan']\n",
    "\n",
    "X_train,y_train=loaddata('train.tsv')\n",
    "X_valid,y_valid=loaddata('val.tsv')\n",
    "X_test,y_test=loaddata('test.tsv')\n",
    "print('train:',len(y_train))\n",
    "print('valid:',len(y_valid))\n",
    "print('test:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4O4oCb93efQ"
   },
   "source": [
    "Preprocessing for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lpD51ZeEgtC"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from torchtext import data\n",
    "import numpy as np\n",
    "\n",
    "# add start token and end token\n",
    "def preprocess(tweets,labels):\n",
    "  field = data.Field(init_token='<S>', eos_token='</S>', pad_token='</S>')\n",
    "  tweets = field.pad(tweets)\n",
    "  print('one tweet after padding:\\n',tweets[0])\n",
    "  t = keras.preprocessing.text.Tokenizer(num_words=64,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', split=' ', char_level = True, oov_token='<#>', document_count=0)\n",
    "  t.fit_on_texts(tweets)\n",
    "  x = t.texts_to_sequences(tweets)\n",
    "  count = 10\n",
    "  vocabulary, out_of_vocabulary =[],[] \n",
    "  i=1\n",
    "  for w,c in t.word_counts.items():\n",
    "    if c < count:\n",
    "      out_of_vocabulary.append(w)\n",
    "    else:\n",
    "      vocabulary.append((w,i))\n",
    "      i+=1\n",
    "  print('\\n number of vocabulary ids:\\n',len(vocabulary))\n",
    "\n",
    "  # after get the number, we can plug it into Tokenizer using num_words=64\n",
    "  voc_table=[(k,v) for k,v in t.word_index.items()]\n",
    "  print('\\ntable of vocabulary ids:\\n',voc_table[:64])\n",
    "  # index for different languages\n",
    "  l = keras.preprocessing.text.Tokenizer(split='\\n')\n",
    "  # fit the tokenizer on the documents\n",
    "  l.fit_on_texts(labels)\n",
    "  y = l.texts_to_sequences(labels)\n",
    "  y = np.asarray(y)\n",
    "  lan_table=[(k,v-1) for k,v in l.word_index.items()]\n",
    "  for i in range(len(y)):\n",
    "    y[i]=y[i]-1\n",
    "  print('\\n\\ntable of language ids:\\n',lan_table)\n",
    "  return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "-oD47ckCSr9E",
    "outputId": "5ed70b54-b3e6-4809-8383-69e66871a12f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one tweet after padding:\n",
      " ['<S>', 'a', 'l', 'e', 'm', 'a', 'n', 'i', 'a', 'v', 's', 'a', 'r', 'g', 'e', 'n', 't', 'i', 'n', 'a', 'l', 'a', 't', 'e', 'r', 'c', 'e', 'r', 'a', 'e', 's', 'l', 'a', 'v', 'e', 'n', 'c', 'i', 'd', 'a', 'e', 'l', 'm', 'u', 'n', 'd', 'i', 'a', 'l', 'd', 'e', 'b', 'r', 'a', 's', 'i', 'l', 'c', 'i', 'e', 'r', 'r', 'a', 'e', 's', 't', 'e', 'd', 'o', 'm', 'i', 'n', 'g', 'o', 'c', 'o', 'n', 'u', 'n', 'a', 'r', 'e', 'e', 'd', 'i', 'c', 'i', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>', '</S>']\n",
      "\n",
      " number of vocabulary ids:\n",
      " 64\n",
      "\n",
      "table of vocabulary ids:\n",
      " [('<#>', 1), ('</s>', 2), ('e', 3), ('a', 4), ('o', 5), ('s', 6), ('i', 7), ('t', 8), ('n', 9), ('r', 10), ('l', 11), ('d', 12), ('u', 13), ('m', 14), ('c', 15), ('h', 16), ('p', 17), ('<s>', 18), ('g', 19), ('b', 20), ('y', 21), ('f', 22), ('v', 23), ('w', 24), ('j', 25), ('k', 26), ('q', 27), ('z', 28), ('x', 29), ('_', 30), ('é', 31), ('á', 32), ('í', 33), ('ã', 34), ('ó', 35), ('ñ', 36), ('ç', 37), ('ú', 38), ('à', 39), ('ê', 40), ('è', 41), ('ü', 42), ('ò', 43), ('õ', 44), ('ä', 45), ('ô', 46), ('â', 47), ('ö', 48), ('º', 49), ('ù', 50), ('č', 51), ('š', 52), ('ć', 53), ('ß', 54), ('ï', 55), ('ì', 56), ('ª', 57), ('ë', 58), ('û', 59), ('о', 60), ('î', 61), ('œ', 62), ('ﾟ', 63), ('ا', 64)]\n",
      "\n",
      "\n",
      "table of language ids:\n",
      " [('en', 0), ('es', 1), ('pt', 2), ('fr', 3), ('ca', 4), ('it', 5), ('de', 6), ('eu', 7), ('gl', 8)]\n"
     ]
    }
   ],
   "source": [
    "x,y = preprocess(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Snxu_o3wSzED"
   },
   "outputs": [],
   "source": [
    "x_valid,y_valid = preprocess(X_valid,y_valid)\n",
    "x_test,y_test = preprocess(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3OAWUDEi3r4l"
   },
   "source": [
    "textCNN model including embedding layer, convolution layer, pooling layer and linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFl6_7Rp-9kP"
   },
   "outputs": [],
   "source": [
    "#multiple filters\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "class textCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs,embedding_dim)) for fs in filter_sizes])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(len(filter_sizes)*n_filters, output_dim)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "                \n",
    "        #embedded = [batch size, length, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1) # add channel dimension\n",
    "        \n",
    "        #embedded = [batch size, 1, length, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs] #parallel computing\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, length - filter_sizes[n]+1]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "       \n",
    "            \n",
    "        return self.linear(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_rdFcga7yNy"
   },
   "source": [
    "training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P4HQph3lB2Hg"
   },
   "outputs": [],
   "source": [
    "def train(model,x,y,batch_size):\n",
    "    \n",
    "    batch_num = int(len(x)/batch_size)\n",
    "    \n",
    "    train_x = Variable(torch.LongTensor(x))\n",
    "    train_y = Variable(torch.LongTensor(y)).squeeze(1)\n",
    "    \n",
    "    for t in range(100):\n",
    "      \n",
    "      epoch_loss = 0\n",
    "      epoch_acc = 0\n",
    "      \n",
    "      print(t)\n",
    "      \n",
    "      for i in range(batch_num):\n",
    "\n",
    "          batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "          batch_y = train_y[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "        \n",
    "          predictions = model(batch_x)\n",
    "          \n",
    "          loss = loss_function(predictions, batch_y)\n",
    "           \n",
    "          acc = accuracy(predictions, batch_y)\n",
    "        \n",
    "          loss.backward()\n",
    "        \n",
    "          optimizer.step()\n",
    "\n",
    "          epoch_loss += loss.item()\n",
    "          epoch_acc += acc.item()\n",
    "     \n",
    "      print(epoch_acc/(batch_num*100))\n",
    "          \n",
    "    return epoch_loss/batch_num, epoch_acc / len(x) # return the average loss and the total accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BkEhXmBPIQuX"
   },
   "outputs": [],
   "source": [
    "# def train(model,x,y,batch_size):\n",
    "    \n",
    "    \n",
    "#     train_x = Variable(torch.LongTensor(x))\n",
    "#     train_y = Variable(torch.LongTensor(y)).squeeze(1)\n",
    "    \n",
    "#     epoch = 10000\n",
    "    \n",
    "#     for t in range(epoch):\n",
    "      \n",
    "#       # randomly choose\n",
    "      \n",
    "#       idx = torch.randperm(len(x))[:batch_size]\n",
    "\n",
    "#       batch_x = train_x[idx]\n",
    "#       batch_y = train_y[idx]\n",
    "\n",
    "#       optimizer.zero_grad()\n",
    "        \n",
    "#       predictions = model(batch_x)\n",
    "          \n",
    "#       loss = loss_function(predictions, batch_y)\n",
    "           \n",
    "#       acc = accuracy(predictions, batch_y)\n",
    "        \n",
    "#       loss.backward()\n",
    "        \n",
    "#       optimizer.step()\n",
    "      \n",
    "#       #print(acc.item()/batch_size)\n",
    "\n",
    "      \n",
    "#     return loss.item(), acc.item()/batch_size# return the average loss and the total accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oA0cwOJOPO3v"
   },
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "   \n",
    "    max_preds = preds.argmax(dim=1, keepdim=True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    num = correct.sum()\n",
    "    return num # return number of correct ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTeI7iTsKe5c"
   },
   "outputs": [],
   "source": [
    "def evaluate(model,x,y):\n",
    "    \n",
    "   \n",
    "    valid_x = Variable(torch.LongTensor(x))\n",
    "    valid_y = Variable(torch.LongTensor(y)).squeeze(1)\n",
    "          \n",
    "    predictions = model(valid_x)\n",
    "    loss = loss_function(predictions, valid_y)\n",
    "    acc = accuracy(predictions, valid_y)\n",
    "        \n",
    "    return loss.item(), acc.item() / len(x),predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TxYWRnqq8erB"
   },
   "source": [
    "try the model, it makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "ZwJWiT4fCdVB",
    "outputId": "60063099-3993-4f02-ace5-4996fb9fe8a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 1.311 | Train Acc: 55.44% |\n",
      "| Epoch: 02 | Train Loss: 0.949 | Train Acc: 70.30% |\n",
      "| Epoch: 03 | Train Loss: 0.855 | Train Acc: 73.36% |\n",
      "| Epoch: 04 | Train Loss: 0.805 | Train Acc: 74.86% |\n",
      "| Epoch: 05 | Train Loss: 0.781 | Train Acc: 75.50% |\n",
      "| Epoch: 06 | Train Loss: 0.760 | Train Acc: 76.00% |\n",
      "| Epoch: 07 | Train Loss: 0.744 | Train Acc: 76.66% |\n",
      "| Epoch: 08 | Train Loss: 0.732 | Train Acc: 76.89% |\n",
      "| Epoch: 09 | Train Loss: 0.723 | Train Acc: 77.06% |\n",
      "| Epoch: 10 | Train Loss: 0.715 | Train Acc: 77.46% |\n",
      "| Epoch: 11 | Train Loss: 0.710 | Train Acc: 77.54% |\n",
      "| Epoch: 12 | Train Loss: 0.703 | Train Acc: 77.70% |\n",
      "| Epoch: 13 | Train Loss: 0.698 | Train Acc: 78.02% |\n",
      "| Epoch: 14 | Train Loss: 0.700 | Train Acc: 77.85% |\n",
      "| Epoch: 15 | Train Loss: 0.698 | Train Acc: 77.86% |\n",
      "| Epoch: 16 | Train Loss: 0.690 | Train Acc: 78.19% |\n",
      "| Epoch: 17 | Train Loss: 0.688 | Train Acc: 78.25% |\n",
      "| Epoch: 18 | Train Loss: 0.691 | Train Acc: 78.13% |\n",
      "| Epoch: 19 | Train Loss: 0.687 | Train Acc: 78.56% |\n",
      "| Epoch: 20 | Train Loss: 0.683 | Train Acc: 78.52% |\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    train_loss, train_acc = train(cnn, optimizer, loss_function)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xuJg-miM8tJ6"
   },
   "source": [
    "Use validation set to choose num of filters :\n",
    "\n",
    "Actually, there are three type of filter sizes,\n",
    "so if Filter_num=10, it means there are 10*3=30 filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "0zfvIR5EB4Za",
    "outputId": "59f9856b-3582-47ce-dd06-9fb81f8fd4db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter_num: 2\n",
      "Train Loss: 0.701 | Train Acc: 77.54% \n",
      "Valid Loss: 1.125 | Valid Acc: 72.75% \n",
      "Filter_num: 5\n",
      "Train Loss: 0.568 | Train Acc: 81.71% \n",
      "Valid Loss: 0.844 | Valid Acc: 78.03% \n",
      "Filter_num: 10\n",
      "Train Loss: 0.440 | Train Acc: 85.93% \n",
      "Valid Loss: 0.840 | Valid Acc: 81.31% \n"
     ]
    }
   ],
   "source": [
    "vocab_size = 64\n",
    "char_dim = 10\n",
    "output_dim = 9\n",
    "filter_sizes = [2,3,4]\n",
    "n_filters=[2,5,10]\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    cnn = textCNN(vocab_size, char_dim, n_filters[i],filter_sizes, output_dim,dropout=0)\n",
    "    optimizer = torch.optim.Adam(cnn.parameters())\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(f'Filter_num: {n_filters[i]:1}')\n",
    "    \n",
    "    train_loss, train_acc = train(cnn,x,y,batch_size=100)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% ')\n",
    "    \n",
    "    valid_loss, valid_acc = evaluate(cnn,x_valid,y_valid)\n",
    "    \n",
    "    print(f'Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}% ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXJEjJXgsxmh"
   },
   "source": [
    "Use more iterations to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmjBdGVvNbZc"
   },
   "outputs": [],
   "source": [
    "vocab_size = 64\n",
    "char_dim = 10\n",
    "output_dim = 9\n",
    "filter_sizes = [2,3,4]\n",
    "n_filters = 10\n",
    "\n",
    "cnn = textCNN(vocab_size, char_dim, n_filters,filter_sizes, output_dim,dropout=0)\n",
    "optimizer = torch.optim.Adam(cnn.parameters())\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "train_loss, train_acc = train(cnn,x,y,batch_size=100)\n",
    "    \n",
    "print(f'Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% ')\n",
    "    \n",
    "valid_loss, valid_acc = evaluate(cnn,x_valid,y_valid)\n",
    "    \n",
    "print(f'Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}% ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cf8LoZ4ZFU6T"
   },
   "source": [
    "Perplexity to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rDoBr59AFUMc",
    "outputId": "1eb04117-3a7e-4c9b-919b-549079d33cf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 0.8650198578834534\n",
      "Entropy: tensor(0.8658)\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_acc, preds = evaluate(cnn,x_valid,y_valid)\n",
    "print('Cross Entropy:',valid_loss)\n",
    "\n",
    "pxs = torch.nn.functional.softmax(Variable(preds), dim=1).data\n",
    "p_x, indices = torch.max(pxs, 1)\n",
    "\n",
    "\n",
    "H_x = torch.sum(p_x)/len(preds)\n",
    "\n",
    "print('Entropy:',H_x.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_zLZoiJ94jN"
   },
   "source": [
    "Use the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vfsE_7Nfr3yj",
    "outputId": "236415c2-5d25-4bc2-a665-b791dbe0a872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.944 | Test Acc: 73.15% \n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(cnn,x_test,y_test)\n",
    "    \n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3unvlK2myiv0"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def Metrics(preds, labs, show=True):\n",
    "#   \"\"\"Print precision, recall and F1 for each language.\n",
    "#   Assumes a single language per example, i.e. no code switching.\n",
    "#   Args:\n",
    "#     preds: list of predictions\n",
    "#     labs: list of labels\n",
    "#     show: flag to toggle printing\n",
    "#   \"\"\"\n",
    "    all_langs = set(preds + labs)\n",
    "    preds = np.array(preds)\n",
    "    labs = np.array(labs)\n",
    "    label_totals = collections.Counter(labs)\n",
    "    pred_totals = collections.Counter(preds)\n",
    "    confusion_matrix = collections.Counter(zip(preds, labs))\n",
    "    num_correct = 0\n",
    "    num_lan = 9\n",
    "    for lang in range(num_lan):\n",
    "        num_correct += confusion_matrix[(lang, lang)]\n",
    "    acc = num_correct / float(len(preds))\n",
    "    print ('accuracy = {0:.3f}'.format(acc))\n",
    "    if show:\n",
    "        print (' Lang     Prec.   Rec.   F1')\n",
    "        print ('------------------------------')\n",
    "    scores = []\n",
    "    fmt_str = '  {0:6}  {1:6.2f} {2:6.2f} {3:6.2f}'\n",
    "    for lang in range(num_lan):\n",
    "        \n",
    "        total = max(1.0, pred_totals[lang])\n",
    "        precision = 100.0 * confusion_matrix[(lang, lang)] / total\n",
    "        \n",
    "        total = max(1.0, label_totals[lang])\n",
    "        recall = 100.0 * confusion_matrix[(lang, lang)] / total\n",
    "        if precision + recall == 0.0:\n",
    "            f1 = 0.0\n",
    "        else:\n",
    "            f1 = 2.0 * precision * recall / (precision + recall)\n",
    "        scores.append([precision, recall, f1])\n",
    "        if show:\n",
    "            print (fmt_str.format(lang, precision, recall, f1))\n",
    "        totals = np.array(scores).mean(axis=0)\n",
    "        if show:\n",
    "            print('------------------------------')\n",
    "    print(fmt_str.format('Total:', totals[0], totals[1], totals[2]))\n",
    "    return totals[2]\n",
    "\n",
    "class MovingAvg(object):\n",
    "  \n",
    "    def __init__(self, p):\n",
    "        self.val = None\n",
    "        self.p = p\n",
    "\n",
    "    def Update(self, v):\n",
    "        if self.val is None:\n",
    "            self.val = v\n",
    "            return v\n",
    "        self.val = self.p * self.val + (1.0 - self.p) * v\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "O1U1K9fbWcnZ",
    "outputId": "97265c55-e3a7-4bab-dd04-6be572c70111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.731\n",
      " Lang     Prec.   Rec.   F1\n",
      "------------------------------\n",
      "       0   79.81  83.65  81.68\n",
      "------------------------------\n",
      "       1   72.80  78.91  75.73\n",
      "------------------------------\n",
      "       2   77.63  74.96  76.27\n",
      "------------------------------\n",
      "       3   44.50  40.27  42.28\n",
      "------------------------------\n",
      "       4   46.94  38.62  42.37\n",
      "------------------------------\n",
      "       5   46.51  26.91  34.09\n",
      "------------------------------\n",
      "       6   77.02  57.14  65.61\n",
      "------------------------------\n",
      "       7    0.62   0.51   0.56\n",
      "------------------------------\n",
      "       8    0.00   0.00   0.00\n",
      "------------------------------\n",
      "  Total:   49.54  44.55  46.51\n"
     ]
    }
   ],
   "source": [
    "test_x = Variable(torch.LongTensor(x_test))\n",
    "test_y = Variable(torch.LongTensor(y_test)).squeeze(1)\n",
    "          \n",
    "output = cnn(test_x)\n",
    "preds = output.argmax(dim=1, keepdim=True).squeeze(1)\n",
    "    \n",
    "total = Metrics(preds,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "byUUd6tuCZ8a",
    "outputId": "6ba8fa71-643f-4b78-e49f-c63967b6ce1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('en', 25979), ('es', 24712), ('pt', 18466), ('fr', 3704), ('ca', 2839), ('it', 1235), ('de', 1157), ('eu', 1051), ('gl', 1032)])\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import operator\n",
    "y_cnt=Counter()\n",
    "for word in y_train:\n",
    "    y_cnt[word]+=1\n",
    "y_cnt=dict(y_cnt)\n",
    "y_freq=OrderedDict(sorted(y_cnt.items(), key=lambda t: t[1],reverse=True))\n",
    "print(y_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NDTUn1_EC94-"
   },
   "source": [
    "Recall that table of language ids:\n",
    "\n",
    " [('en', 0), ('es', 1), ('pt', 2), ('fr', 3), ('ca', 4), ('it', 5), ('de', 6), ('eu', 7), ('gl', 8)]\n",
    " \n",
    " It seems that the language with larger frequency will have larger F1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
