{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from random import randint\n",
    "from scipy.io import loadmat\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = loadmat(filename)\n",
    "    X = data['data']\n",
    "    Y = data['info'][0]\n",
    "    X_train = np.zeros((len(X),X[0,0].shape[1]))\n",
    "    for i in range(len(X)):\n",
    "        X_train[i,:]=X[i,0] \n",
    "        \n",
    "    # build word-id dictionary\n",
    "    with open('dictionary.txt') as f:\n",
    "        words = [l.strip() for l in f if l.strip()]\n",
    "    Y_train = np.zeros((360,2))\n",
    "    \n",
    "    # preprocess Y train\n",
    "    for i in range(360):\n",
    "        Y_train[i,0] = words.index(Y[i]['word'][0])+1 # get the word id from the dictionary\n",
    "        Y_train[i,1] = randint(1, 60)\n",
    "        \n",
    "    return X_train,Y_train,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data...\n",
      "shape of X train: (2700, 500)\n",
      "shape of X test: (540, 500)\n",
      "shape of Y train: (2700, 218)\n",
      "shape of Y test: (540, 218)\n"
     ]
    }
   ],
   "source": [
    "Yp = 218\n",
    "ntrain = 2700\n",
    "ntest = 540\n",
    "print('load data...') \n",
    "X1,wid1,data1 = load_data('data-science-P1.mat')\n",
    "X2,wid2,data2 = load_data('data-science-P2.mat')\n",
    "X3,wid3,data3 = load_data('data-science-P3.mat')\n",
    "X4,wid4,data4 = load_data('data-science-P4.mat')\n",
    "X5,wid5,data5 = load_data('data-science-P5.mat')\n",
    "X6,wid6,data6 = load_data('data-science-P6.mat')\n",
    "X7,wid7,data7 = load_data('data-science-P7.mat')\n",
    "X8,wid8,data8 = load_data('data-science-P8.mat')\n",
    "X9,wid9,data9 = load_data('data-science-P9.mat')\n",
    "\n",
    "dim = min(X1.shape[1],X2.shape[1],X3.shape[1],X4.shape[1],X5.shape[1],X6.shape[1],X7.shape[1],X8.shape[1],X9.shape[1])\n",
    "X = np.vstack((X1[:,:dim],X2[:,:dim],X3[:,:dim],X4[:,:dim],X5[:,:dim],X6[:,:dim],X7[:,:dim],X8[:,:dim],X9[:,:dim]))\n",
    "wid = np.vstack((wid1,wid2,wid3,wid4,wid5,wid6,wid7,wid8,wid9))\n",
    "data = np.vstack((data1,data2,data3,data4,data5,data6,data7,data8,data9))\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=500)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "word_feature=io.mmread('word_feature_centered.mtx')\n",
    "\n",
    "X_train,X_test,wid_train,wid_test = train_test_split(X,wid,test_size=1/6,random_state=42)\n",
    "\n",
    "# separate data set\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "\n",
    "# from word id to Y_train (300,1) and Y_test (60,2)\n",
    "Y_train = np.zeros((ntrain,Yp))\n",
    "Y_test = np.zeros((ntest,Yp))\n",
    "Y2_test = np.zeros((ntest,Yp))\n",
    "for i in range(ntrain):\n",
    "    for j in range(Yp):\n",
    "        Y_train[i][j]=word_feature[int(wid_train[i,0])-1][j]\n",
    "for i in range(ntest):\n",
    "    for j in range(Yp):\n",
    "        Y_test[i][j]=word_feature[int(wid_test[i,0])-1][j]\n",
    "        Y2_test[i][j]=word_feature[int(wid_test[i,1])-1][j]\n",
    "\n",
    "print('shape of X train:',X_train.shape)\n",
    "print('shape of X test:',X_test.shape)\n",
    "print('shape of Y train:',Y_train.shape)\n",
    "print('shape of Y test:',Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoShooting:\n",
    "    def __init__(self, X, Y, lamda):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.n = X.shape[0]\n",
    "        self.p = X.shape[1]\n",
    "        self.lamda = lamda\n",
    "        self.w = np.zeros(self.p)\n",
    " \n",
    "    def shoot(self):\n",
    "        stop=False\n",
    "        X = self.X\n",
    "        w = self.w\n",
    "        t=0\n",
    "        epsilon=1e-4\n",
    "        max_iter=10\n",
    "        while not stop and t<max_iter:\n",
    "            w_pre = w.copy()\n",
    "            for j in range(self.p):\n",
    "                #j = randint(0,self.p-1)\n",
    "                w_nonj = np.delete(w,j)\n",
    "                X_nonj = np.delete(X,j,1)  # delete k_th column\n",
    "                w_j = w[j]*np.ones((self.n,1))\n",
    "                r_j = X_nonj.dot(w_nonj)-self.Y\n",
    "                c_j = np.sum(np.multiply(X[:,j],r_j))\n",
    "                a_j = np.sum(X[:,j]**2)\n",
    "                if c_j > self.lamda:\n",
    "                    w[j] = (-c_j+self.lamda)/a_j\n",
    "                elif c_j < (-self.lamda):\n",
    "                    w[j] = (-c_j-self.lamda)/a_j\n",
    "                else:\n",
    "                    w[j] = 0  \n",
    "            if max(abs(w-w_pre))<=epsilon:\n",
    "                stop=True\n",
    "            t+=1    \n",
    "        self.w =w         \n",
    "    \n",
    "    def predict(self,X,w):\n",
    "        return X.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1(pred,y_true,y_wrong):\n",
    "    score = 0\n",
    "    for i in range(len(pred)):\n",
    "        d1 = np.sum(np.abs(pred[i]-y_true[i]))\n",
    "        d2 = np.sum(np.abs(pred[i]-y_wrong[i]))\n",
    "        if d1<d2:\n",
    "            score+=1\n",
    "        elif d1==d2:\n",
    "            score+=0.5\n",
    "    return score\n",
    "    \n",
    "def L2(pred,y_true,y_wrong):\n",
    "    score = 0\n",
    "    for i in range(len(pred)):\n",
    "        d1 = np.sum((pred[i]-y_true[i])**2)\n",
    "        d2 = np.sum((pred[i]-y_wrong[i])**2)\n",
    "        if d1<d2:\n",
    "            score+=1\n",
    "        elif d1==d2:\n",
    "            score+=0.5\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "weight = np.zeros((X_train.shape[1],Y_train.shape[1]))\n",
    "for j in range(Yp):\n",
    "    print(j)\n",
    "    ls = LassoShooting(X_train,Y_train[:,j],0.15)\n",
    "    ls.shoot()\n",
    "    weight[:,j]=ls.w\n",
    "y_hat = ls.predict(X_test,weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------All Persons--------\n",
      "Accuracy for L1: 0.649074074074074\n",
      "Accuracy for L2: 0.6509259259259259\n"
     ]
    }
   ],
   "source": [
    "print('---------All Persons--------')\n",
    "print('Accuracy for L1:',L1(y_hat,Y_test,Y2_test)/len(Y_test))\n",
    "print('Accuracy for L2:',L2(y_hat,Y_test,Y2_test)/len(Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
